{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lesson1: Convolutional Neural Networks with dogscats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's classify images using deep learning and submit the result to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes Keras with Theano backend.\n",
    "- TODO: make TensorFlow version as another notebook\n",
    "\n",
    "It also assumes that you will run it on either one of these two cases:\n",
    "- Floydhub (--env theano:py2 -> Theano rel-0.8.2 + Keras 1.2.2 on Python2)\n",
    "- local conda virtual environment (Theano 0.9.0 + Keras 2.0.4 on Python3)\n",
    "\n",
    "Refer to [this FloydHub document](http://docs.floydhub.com/home/environments/) for available FloydHub environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have these files in the parent directory of the directory where you execute this notebook.\n",
    "\n",
    "- available [in the official repo](https://github.com/fastai/courses/tree/master/deeplearning1/nbs) for Keras1 on Python2 (rename from original files)\n",
    "    - utils_keras1.py\n",
    "    - vgg16_keras1.py\n",
    "    - vgg16bn_keras1.py\n",
    "- available [in the unofficial repo](https://github.com/roebius/deeplearning1_keras2/tree/master/nbs) for Keras2 on Python3\n",
    "    - utils.py\n",
    "    - vgg16.py\n",
    "    - vgg16bn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory structure looks like this. Please modifiy the symlinks according to your environment.\n",
    "\n",
    "- (*) only for FloydHub\n",
    "- (**) only for local\n",
    "\n",
    "```\n",
    "floyd_requirements.txt (*)\n",
    "floydhub.data.unzip/   (*)\n",
    "floydhub.data.zipped/  (*)\n",
    "    dogscats.zip\n",
    "lesson1/\n",
    "    data/ (**)\n",
    "        redux/\n",
    "            train/\n",
    "                cat.437.jpg\n",
    "                dog.9924.jpg\n",
    "                ...\n",
    "            test/\n",
    "                231.jpg\n",
    "                325.jpg\n",
    "                ...\n",
    "    dogscats_run.ipynb\n",
    "    floyd_requirements.txt -> ../floyd_requirements.txt (*)\n",
    "    utils.py -> ../utils(_keras1).py\n",
    "    vgg16.py -> ../vgg16(_keras1).py\n",
    "    vgg16bn.py -> ../vgg16bn(_keras1).py\n",
    "utils.py\n",
    "utils_keras1.py\n",
    "vgg16.py\n",
    "vgg16_keras1.py\n",
    "vgg16bn.py\n",
    "vgg16bn_keras1.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of data preparation largely depends on which dataset you use. In this section, we will use a pre-organized dataset from http://files.fast.ai/files/dogscats.zip\n",
    "\n",
    "For another example of data preparation, please refer to [this notebook](../lesson1_17flowers/17flowers_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the dataset looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the dogscats.zip file, the directory structure look like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dogscats/\n",
    "    models/\n",
    "    sample/\n",
    "        train/\n",
    "            cats/\n",
    "                cat.394.jpg\n",
    "                ... (8 items)\n",
    "            dogs/\n",
    "                dog.1402.jpg\n",
    "                ... (8 items)\n",
    "        valid/\n",
    "            cats/\n",
    "                cat.10435.jpg\n",
    "                ... (4 items)\n",
    "            dogs/\n",
    "                dog.10459.jpg\n",
    "                ... (4 items)\n",
    "            features.npy\n",
    "            labels.npy\n",
    "    test1/\n",
    "        1.jpg\n",
    "        10.jpg\n",
    "        100.jpg\n",
    "        ... (12500 items)\n",
    "    train/\n",
    "        cats/\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            cat.3.jpg\n",
    "            ... (11500 items)\n",
    "        dogs/\n",
    "            cat.0.jpg\n",
    "            cat.1.jpg\n",
    "            cat.2.jpg\n",
    "            cat.4.jpg\n",
    "            ... (11500 items)\n",
    "    valid/\n",
    "        cats/\n",
    "            cat.2.jpg\n",
    "            cat.5.jpg\n",
    "            ... (1000 item. these are copied from train/cats/ directory)\n",
    "        dogs/\n",
    "            dog.3.jpg\n",
    "            dog.9.jpg\n",
    "            ... (1000 item. these are copied from train/dogs/ directory)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FloydHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows how to update data to FloydHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# from the directory which this notebook is executed\n",
    "cd ../floydhub.data.zipped/; pwd\n",
    "\n",
    "# expected: empty\n",
    "ls -l\n",
    "\n",
    "wget http://files.fast.ai/files/dogscats.zip\n",
    "\n",
    "# upload the zipped dataset to floydnet, and create a floydnet dataset\n",
    "floyd data init dogscats.zipped\n",
    "floyd data upload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the data we have just uploaded to FloydHub, let's unzip it on FloydHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "# from the directory which this notebook is executed\n",
    "cd ../floydhub.fast.ai.data.unzip/; pwd\n",
    "\n",
    "# expected: empty\n",
    "ls -l\n",
    "\n",
    "floyd init dogscats.unzip\n",
    "floyd run --gpu --data [data ID of the uploaded zip] \"unzip /input/dogscats.zip -d /output\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note:\n",
    "- the data ID should be the one you see from the above step\n",
    "- the mounted data is available in /input/ directory, and you need to direct the unzipped files to /output/ directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the notebook in the environment of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# from the directory which this notebook is executed\n",
    "cd ./; pwd\n",
    "\n",
    "# FloydHub\n",
    "floyd init dogscats\n",
    "floyd run --mode jupyter --data [data ID of unzipped data] --env theano:py2 --gpu\n",
    "\n",
    "# alternatively, for local\n",
    "#jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mkdir ~/.keras\n",
    "\n",
    "# FloydHub (Keras1)\n",
    "echo '{\n",
    "    \"image_dim_ordering\": \"th\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"theano\"\n",
    "}' > ~/.keras/keras.json\n",
    "\n",
    "# alternatively, for local (Keras2)\n",
    "#echo '{\n",
    "#    \"image_data_format\": \"channels_first\",\n",
    "#    \"backend\": \"theano\",\n",
    "#    \"floatx\": \"float32\",\n",
    "#    \"epsilon\": 1e-07\n",
    "#}' > ~/.keras/keras.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's start running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make some Python3 functions available on Python2\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "\n",
    "import theano\n",
    "print(theano.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FloydHub: check data\n",
    "%ls /input/dogscats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check current directory\n",
    "%pwd\n",
    "%ls\n",
    "\n",
    "# see some files are loaded fine\n",
    "%cat floyd_requirements.txt\n",
    "\n",
    "# check no Keras2 specific function is used (when Keras1 is used)\n",
    "%cat utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "LESSON_HOME_DIR = current_dir\n",
    "\n",
    "# FloydHub\n",
    "DATA_HOME_DIR = \"/input/dogscats/\"\n",
    "OUTPUT_HOME_DIR = \"/output/\"\n",
    "\n",
    "# alternatively, for local\n",
    "#DATA_HOME_DIR = current_dir+'/data/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test1/' #We use all the test data\n",
    "\n",
    "# FloydHub\n",
    "# data needs to be output under /output\n",
    "# if results_path cannot be created, execute mkdir directly in the terminal\n",
    "results_path = OUTPUT_HOME_DIR + '/results/'\n",
    "%mkdir results_path\n",
    "\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a pretrained VGG model with our Vgg16 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended.\n",
    "#batch_size = 8\n",
    "batch_size = 64\n",
    "\n",
    "no_of_epochs=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original pre-trained Vgg16 class classifies images into one of the 1000 categories. This number of categories depends on the dataset which Vgg16 was trained with. (http://image-net.org/challenges/LSVRC/2014/browse-synsets)\n",
    "\n",
    "In order to classify images into the categories which we prepare (2 categories of dogs/cats, in this notebook), *fine-tuning* technology is useful. It:\n",
    "- keeps the most weights from the pre-trained Vgg16 model, but modifies only a few parts of the weights\n",
    "- changes the dimension of the output layer (from 1000 to 2, in this notebook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab a few images at a time for training and validation.\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "\n",
    "# Finetune: note that the vgg model is compiled inside the finetune method.\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit: note that we are passing in the validation dataset to the fit() method\n",
    "# For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "\n",
    "# FloydHub (Keras1)\n",
    "for epoch in range(no_of_epochs):\n",
    "    print(\"Running epoch: %d\" % epoch)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print(\"Completed %s fit operations\" % no_of_epochs)\n",
    "\n",
    "# alternatively, for local (Keras2)\n",
    "\"\"\"\n",
    "for epoch in range(no_of_epochs):\n",
    "    print(\"Running epoch: %d\" % epoch)\n",
    "    vgg.fit(batches, val_batches, batch_size, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print(\"Completed %s fit operations\" % no_of_epochs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT_HOME_DIR, not DATA_HOME_DIR due to FloydHub restriction\n",
    "%cd $OUTPUT_HOME_DIR\n",
    "%mkdir -p test1/unknown\n",
    "\n",
    "%cd $OUTPUT_HOME_DIR/test1\n",
    "%cp $test_path/*.jpg unknown/\n",
    "\n",
    "# rewrite test_path\n",
    "test_path = OUTPUT_HOME_DIR + '/test1/' #We use all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(preds[:5])\n",
    "\n",
    "filenames = batches.filenames\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can verify the column ordering by viewing some images\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save our test results arrays so we can use them again later\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO) look at data to improve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section also depends on which dataset you use (and which Kaggle competition you are participating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print(\"Raw Predictions: \" + str(isdog[:5]))\n",
    "print(\"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)]))\n",
    "print(\"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sneaky trick to round down our edge predictions\n",
    "# Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FloydHub\n",
    "%cd $OUTPUT_HOME_DIR\n",
    "\n",
    "# alternatively, for local\n",
    "#%cd $DATA_HOME_DIR\n",
    "\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# FloydHub\n",
    "%cd $OUTPUT_HOME_DIR\n",
    "FileLink(submission_file_name)\n",
    "\n",
    "# alternatively, for local\n",
    "#%cd $LESSON_HOME_DIR\n",
    "#FileLink('data/redux/'+submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py3tf)",
   "language": "python",
   "name": "conda_py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
